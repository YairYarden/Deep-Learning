{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOjrzRgWDvyl"
      },
      "source": [
        "# Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hqb6PIfeyi9",
        "outputId": "f36d920c-c20a-4b63-d92f-d6d798880060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import ssl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# check if CUDA is available\n",
        "is_gpu_available = torch.cuda.is_available()\n",
        "\n",
        "if not is_gpu_available:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "DIR_PATH = '/content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOIRwCg62eyL",
        "outputId": "17af3bce-a72b-4bdf-b11d-20ad0d26b075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "OR2tlv5PxtYT"
      },
      "outputs": [],
      "source": [
        "params = {'batch_size'    : 20,\n",
        "          'seq_length'    : 20,\n",
        "          'hidden_size'   : 200,\n",
        "          'num_layers'    : 2,\n",
        "          'embed_size'    : 200,\n",
        "          'dropout'       : 0.0002,\n",
        "          'lr'            : 0.01,\n",
        "          'lr_decay'      : 1.3,\n",
        "          'max_grad_norm' : 2,\n",
        "          'epochs'        : 5\n",
        "          }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF4ND1uxD5YT"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07nDtn7U2qaD",
        "outputId": "dfc9999e-3123-4863-94bc-4f68291503cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526/ptb.train.txt, size of data = 929589\n",
            "46479\n",
            "torch.Size([929580])\n",
            "Loading /content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526/ptb.valid.txt, size of data = 73760\n",
            "3688\n",
            "torch.Size([73760])\n",
            "Loading /content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526/ptb.test.txt, size of data = 82430\n",
            "4121\n",
            "torch.Size([82420])\n"
          ]
        }
      ],
      "source": [
        "train_file_name = f'{DIR_PATH}/ptb.train.txt'\n",
        "val_file_name = f'{DIR_PATH}/ptb.valid.txt'\n",
        "test_file_name = f'{DIR_PATH}/ptb.test.txt'\n",
        "\n",
        "word2idx = {}\n",
        "\n",
        "def load_data(fname, batch_size, dictionary={}):\n",
        "  with open(fname, 'r') as f:\n",
        "    data_str = f.read()\n",
        "  data = data_str.replace('\\n', '<eof>')\n",
        "  data = data.split()\n",
        "  print(\"Loading {}, size of data = {}\".format(fname, len(data)))\n",
        "\n",
        "  x = torch.LongTensor(len(data))\n",
        "  vocab_idx = len(dictionary)\n",
        "  for i in range(len(data)):\n",
        "    if data[i] not in dictionary:\n",
        "      dictionary[data[i]] = vocab_idx\n",
        "      vocab_idx += 1\n",
        "    x[i] = dictionary[data[i]]\n",
        "\n",
        "  num_batches = x.size(0) // batch_size\n",
        "  x = x[:num_batches * batch_size]\n",
        "  print(num_batches)\n",
        "  print(x.size())\n",
        "  return x.view(batch_size, -1), dictionary\n",
        "\n",
        "train_data, word2idx = load_data(train_file_name, params['batch_size'])\n",
        "val_data, word2idx = load_data(val_file_name, params['batch_size'], dictionary=word2idx)\n",
        "test_data, word2idx = load_data(test_file_name, params['batch_size'], dictionary=word2idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx)\n",
        "print(vocab_size)\n",
        "print('Training size: {}'.format(train_data.size()))\n",
        "print('Validation size: {}'.format(val_data.size()))\n",
        "print('Test size: {}'.format(test_data.size()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnU-CyWrWWuO",
        "outputId": "a4784894-1c80-45a8-c48b-a9c585e80b65"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "Training size: torch.Size([20, 46479])\n",
            "Validation size: torch.Size([20, 3688])\n",
            "Test size: torch.Size([20, 4121])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGAzTMPz6l-w"
      },
      "source": [
        "# Define The Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hN79J5ijq8As"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import dropout\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout_prob, use_lstm=False):\n",
        "    super(Net, self).__init__()\n",
        "    self.n_hidden = hidden_size\n",
        "    self.n_layers = num_layers\n",
        "\n",
        "    self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "    if use_lstm:\n",
        "      self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "    else:\n",
        "      self.rnn = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "              weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "    return hidden\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = self.dropout(self.embed(x))\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "    out = self.dropout(out)\n",
        "    out = out.reshape(-1, self.n_hidden)\n",
        "    out = self.fc(out)\n",
        "    return out, hidden\n",
        "\n",
        "model = Net(vocab_size, params['embed_size'], params['hidden_size'], params['num_layers'], params['dropout']).to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma = params['lr_decay'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxc25lbwECa8"
      },
      "source": [
        "# Functions For Training the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "gX3DdqCgCvy7"
      },
      "outputs": [],
      "source": [
        "def evaluate(net, data, criterion, params, is_gpu_available):\n",
        "  running_loss = 0.0\n",
        "  batch_size = data.size(0)\n",
        "  hidden = net.init_hidden(batch_size)\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    for i in range(0, data.size(1) - params['seq_length'], params['seq_length']):\n",
        "      x = data[:, i: i + params['seq_length']]\n",
        "      y = data[:, i + 1: i + 1 + params['seq_length']]\n",
        "      if is_gpu_available:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "      # Creating new variables for the hidden state, otherwise\n",
        "      # we'd backprop through the entire training history\n",
        "      hidden = tuple([each.data for each in hidden])\n",
        "\n",
        "      output, hidden = net(x, hidden)\n",
        "      loss = criterion(output, y.reshape(batch_size*params['seq_length']))\n",
        "\n",
        "      running_loss += loss.item()\n",
        "  \n",
        "  valid_loss = running_loss / (data.size(1) // params['seq_length'])\n",
        "  return valid_loss\n",
        "\n",
        "def train(net, data, criterion, opt, params, is_gpu_available):\n",
        "  running_loss = 0.0\n",
        "  batch_size = data.size(0)\n",
        "  hidden = net.init_hidden(batch_size)\n",
        "  net.train()\n",
        "  for i in range(0, data.size(1) - params['seq_length'], params['seq_length']):\n",
        "    x = data[:, i: i + params['seq_length']]\n",
        "    y = data[:, i + 1: i + 1 + params['seq_length']]\n",
        "    if is_gpu_available:\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    hidden = tuple([each.data for each in hidden])\n",
        "    net.zero_grad()\n",
        "    output, hidden = net(x, hidden)\n",
        "    loss = criterion(output, y.reshape(batch_size*params['seq_length']))\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(net.parameters(), params['max_grad_norm'])\n",
        "    opt.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  \n",
        "  epoch_loss = running_loss / (data.size(1) // params['seq_length'])\n",
        "  return net, opt, epoch_loss\n",
        "\n",
        "def training_loop(train_data, val_data, net, opt, criterion, scheduler, params, is_gpu_available):\n",
        "  # set objects for storing metrics\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_perp_vec = []\n",
        "    val_perp_vec = []\n",
        "\n",
        "    print(f'{datetime.now().time().replace(microsecond=0)} START')\n",
        "\n",
        "    # Train model\n",
        "    for epoch in range(0, params['epochs']):\n",
        "      net, optimizer, train_loss = train(net, train_data, criterion, opt, params, is_gpu_available)\n",
        "      train_perp = np.exp(train_loss)\n",
        "      train_losses.append(train_loss)\n",
        "      train_perp_vec.append(train_perp)\n",
        "      scheduler.step()\n",
        "\n",
        "      # validation\n",
        "      val_loss = evaluate(net, val_data, criterion, params, is_gpu_available)\n",
        "      val_perp = np.exp(val_loss)\n",
        "      val_losses.append(val_loss)\n",
        "      val_perp_vec.append(val_perp)\n",
        "\n",
        "      print(\n",
        "          f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "          f'Epoch: {epoch}\\t'\n",
        "          f'Train loss: {train_loss:.4f}\\t'\n",
        "          f'Val loss: {val_loss:.4f}\\t'\n",
        "          f'Train perplexity: {train_perp:.4f}\\t'\n",
        "          f'Test perplexity: {val_perp:.4f}'\n",
        "        )\n",
        "      \n",
        "    return net, opt, (train_losses, val_losses), (train_perp_vec, val_perp_vec)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pxcAkJTTbSV",
        "outputId": "56383c40-e181-4c56-fdb1-d730169230bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:22:49 START\n"
          ]
        }
      ],
      "source": [
        "model = Net(vocab_size, params['embed_size'], params['hidden_size'], params['num_layers'], params['dropout']).to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=params['lr_decay'])\n",
        "model = training_loop(train_data, val_data, model, optimizer, criterion, lr_scheduler, params, is_gpu_available)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dSQIDuJpTxKQ"
      },
      "outputs": [],
      "source": [
        "def plot_train_and_valid_losses(train_losses, test_losses, train_type=None):\n",
        "  train_losses = np.array(train_losses) \n",
        "  test_losses = np.array(test_losses)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (8, 4.5))\n",
        "\n",
        "  ax.plot(train_losses, color='blue', label='Training loss') \n",
        "  ax.plot(test_losses, color='red', label='Validation loss')\n",
        "  title = \"Loss over epochs\"\n",
        "  if train_type:\n",
        "    title += \"\\n\" + train_type\n",
        "  ax.set(title=title, \n",
        "          xlabel='Epoch',\n",
        "          ylabel='Loss') \n",
        "  ax.legend()\n",
        "  plt.grid()\n",
        "  fig.show()\n",
        "    # --------------------------------------------------------------------------------------------------\n",
        "def plot_train_and_valid_perp(train_perp, valid_perp, train_type=None):\n",
        "  train_perp = np.array(train_perp) \n",
        "  valid_perp = np.array(valid_perp)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (8, 4.5))\n",
        "\n",
        "  ax.plot(train_perp, color='blue', label='Training Perplexity') \n",
        "  ax.plot(valid_perp, color='red', label='Validation Perplexity')\n",
        "  title = \"Perplexity over epochs\"\n",
        "  if train_type:\n",
        "    title += \"\\n\" + train_type\n",
        "  ax.set(title=title, \n",
        "          xlabel='Epoch',\n",
        "          ylabel='Perplexity') \n",
        "  ax.legend()\n",
        "  fig.show()\n",
        "  \n",
        "  return fig\n",
        "# --------------------------------------------------------------------------------------------------\n",
        "def save_model(model, optimizer, dir_path, train_type=None):\n",
        "  # create checkpints folder\n",
        "  checkpoint_folder = os.path.join(dir_path, 'checkpoints')\n",
        "  os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "  # save model\n",
        "  curr_datetime = datetime.now().strftime(\"%y_%m_%d_%H:%M:%S\")\n",
        "  model_name = f'{curr_datetime}'.replace(':', '_')\n",
        "  if train_type:\n",
        "    model_name = train_type + '_' + model_name\n",
        "    # model_name = train_type\n",
        "  ckpt_path = os.path.join(checkpoint_folder, f'{model_name}.ckpt')\n",
        "  torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'use_dropout': model.use_dropout,\n",
        "    'use_batchnorm': model.use_batchnorm,\n",
        "    \n",
        "  }, ckpt_path)\n",
        "\n",
        "  print(f'model saved to \"{ckpt_path}\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vuBYewv8jqKY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Ex2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}