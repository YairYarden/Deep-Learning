{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "BOjrzRgWDvyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hqb6PIfeyi9",
        "outputId": "47b46627-7336-4fe7-f70a-048acf1666b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available.  Training on CPU ...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import ssl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# check if CUDA is available\n",
        "is_gpu_available = torch.cuda.is_available()\n",
        "\n",
        "if not is_gpu_available:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "DIR_PATH = '/content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOIRwCg62eyL",
        "outputId": "62fb06be-3d81-4d72-f287-087cb9d4fc56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'batch_size'    : 20,\n",
        "          'seq_length'       : 20,\n",
        "          'hidden_size'   : 200,\n",
        "          'num_layers'    : 2,\n",
        "          'embed_size'    : 200,\n",
        "          'dropout'       : 0.2,\n",
        "          'lr'            : 1,\n",
        "          'lr_decay'      : 1.2,\n",
        "          'max_grad_norm' : 3,\n",
        "          'epochs'        : 2\n",
        "          }"
      ],
      "metadata": {
        "id": "OR2tlv5PxtYT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "IF4ND1uxD5YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_name = f'{DIR_PATH}/ptb.train.txt'\n",
        "val_file_name = f'{DIR_PATH}/ptb.valid.txt'\n",
        "test_file_name = f'{DIR_PATH}/ptb.test.txt'\n",
        "\n",
        "word2idx = {}\n",
        "\n",
        "def load_data(fname, batch_size, dictionary={}):\n",
        "  with open(fname, 'r') as f:\n",
        "    data_str = f.read()\n",
        "  data = data_str.replace('\\n', '<eof>')\n",
        "  data = data.split()\n",
        "  print(\"Loading {}, size of data = {}\".format(fname, len(data)))\n",
        "\n",
        "  x = torch.LongTensor(len(data))\n",
        "  vocab_idx = len(dictionary)\n",
        "  for i in range(len(data)):\n",
        "    if data[i] not in dictionary:\n",
        "      dictionary[data[i]] = vocab_idx\n",
        "      vocab_idx += 1\n",
        "    x[i] = dictionary[data[i]]\n",
        "\n",
        "  num_batches = x.size(0) // batch_size\n",
        "  x = x[:num_batches * batch_size]\n",
        "  return x.view(batch_size, -1), dictionary\n",
        "\n",
        "train_data, word2idx = load_data(train_file_name, params['batch_size'])\n",
        "val_data, word2idx = load_data(val_file_name, params['batch_size'], dictionary=word2idx)\n",
        "test_data, word2idx = load_data(test_file_name, params['batch_size'], dictionary=word2idx)\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "print(vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07nDtn7U2qaD",
        "outputId": "e266fe34-e82f-49b9-bea9-68c3effc9d73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526/ptb.train.txt, size of data = 929589\n",
            "10000\n",
            "Loading /content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526/ptb.valid.txt, size of data = 73760\n",
            "10000\n",
            "Loading /content/drive/MyDrive/Deep learning 05107255/ex2_316168061_313471526/ptb.test.txt, size of data = 82430\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define The Network"
      ],
      "metadata": {
        "id": "CGAzTMPz6l-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import dropout\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout_prob):\n",
        "    super(Net, self).__init__()\n",
        "    self.n_hidden = hidden_size\n",
        "    self.n_layers = num_layers\n",
        "\n",
        "    self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "    self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "              weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "    return hidden\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = self.dropout(self.embed(x))\n",
        "    out, hidden = self.lstm(x, hidden)\n",
        "    out = self.dropout(out)\n",
        "    out = out.contiguous().view(-1, self.n_hidden)\n",
        "    out = self.fc(out)\n",
        "    return out, hidden\n",
        "\n",
        "model = Net(vocab_size, params['embed_size'], params['hidden_size'], params['num_layers'], params['dropout'])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma = params['lr_decay'])"
      ],
      "metadata": {
        "id": "hN79J5ijq8As"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions For Training the network"
      ],
      "metadata": {
        "id": "qxc25lbwECa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net, data, criterion, params, is_gpu_available):\n",
        "  running_loss = 0.0\n",
        "  batch_size = data.size(0)\n",
        "  hidden = net.init_hidden(batch_size)\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    for i in range(0, data.size(1) - params['seq_length'], params['seq_length']):\n",
        "      x = data[:, i: i + params['seq_length']].to(DEVICE)\n",
        "      y = data[:, i + 1: i + 1 + params['seq_length']].to(DEVICE)\n",
        "      if is_gpu_available:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "      # Creating new variables for the hidden state, otherwise\n",
        "      # we'd backprop through the entire training history\n",
        "      hidden = tuple([each.data for each in hidden])\n",
        "\n",
        "      output, hidden = net(x, hidden)\n",
        "      loss = criterion(output, y.reshape(batch_size*params['seq_length']))\n",
        "\n",
        "      running_loss += loss\n",
        "  \n",
        "  valid_loss = running_loss / (data.size(1) // params['seq_length'])\n",
        "  return valid_loss\n",
        "\n",
        "def train(net, data, criterion, opt, params, is_gpu_available):\n",
        "  running_loss = 0.0\n",
        "  batch_size = data.size(0)\n",
        "  hidden = net.init_hidden(batch_size)\n",
        "  net.train()\n",
        "  for i in range(0, data.size(1) - params['seq_length'], params['seq_length']):\n",
        "    x = data[:, i: i + params['seq_length']].to(DEVICE)\n",
        "    y = data[:, i + 1: i + 1 + params['seq_length']].to(DEVICE)\n",
        "    if is_gpu_available:\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    hidden = tuple([each.data for each in hidden])\n",
        "    net.zero_grad()\n",
        "    output, hidden = net(x, hidden)\n",
        "    loss = criterion(output, y.reshape(batch_size*params['seq_length']))\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(net.parameters(), params['max_grad_norm'])\n",
        "    opt.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  \n",
        "  epoch_loss = running_loss / (data.size(1) // params['seq_length'])\n",
        "  return net, opt, epoch_loss\n",
        "\n",
        "def training_loop(train_data, val_data, net, opt, criterion, params, is_gpu_available):\n",
        "  # set objects for storing metrics\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_perp_vec = []\n",
        "    val_perp_vec = []\n",
        "\n",
        "    print(f'{datetime.now().time().replace(microsecond=0)} START')\n",
        "\n",
        "    # Train model\n",
        "    for epoch in range(0, params['epochs']):\n",
        "      net, optimizer, train_loss = train(net, train_data, criterion, opt, params, is_gpu_available)\n",
        "      train_perp = torch.exp(train_loss)\n",
        "      train_losses.append(train_loss)\n",
        "      train_perp_vec.append(train_perp)\n",
        "\n",
        "      # validation\n",
        "      model, val_loss = evaluate(net, val_data, criterion, params, is_gpu_available)\n",
        "      val_perp = torch.exp(val_loss)\n",
        "      val_losses.append(val_loss)\n",
        "      val_perp_vec.append(val_perp)\n",
        "\n",
        "      print(\n",
        "          f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "          f'Epoch: {epoch}\\t'\n",
        "          f'Train loss: {train_loss:.4f}\\t'\n",
        "          f'Val loss: {val_loss:.4f}\\t'\n",
        "          f'Train perplexity: {train_perp:.4f}\\t'\n",
        "          f'Test perplexity: {val_perp:.4f}'\n",
        "        )\n",
        "      \n",
        "    return net, opt, (train_losses, val_losses), (train_perp_vec, val_perp_vec)\n",
        "\n"
      ],
      "metadata": {
        "id": "gX3DdqCgCvy7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(train_data, val_data, model, optimizer, criterion, params, is_gpu_available)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pxcAkJTTbSV",
        "outputId": "48d2344a-a253-4a07-c629-82d6cd4414b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20:30:49 START\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dSQIDuJpTxKQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}